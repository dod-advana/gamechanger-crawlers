import scrapy
import re
import bs4
from ..items import DocumentItem
from ..data_model import Document, DownloadableItem
from ..utils import abs_url


class NAMESpider(scrapy.Spider):
    name = 'NAME'

    start_urls = ['URL']

    def parse(self, response):
        links = response.css('li.col-sm-6')[0].css('a')
        yield from response.follow_all(links[4:-1], self.parse_documents)


    def parse_documents(self, response):

        # page_url = response.url
        #
        # # parse html response
        # base_url = 'https://www.esd.whs.mil'
        # soup = bs4.BeautifulSoup(response.body, features="html.parser")
        # table = soup.find('table', attrs={'class': 'dnnGrid'})
        # rows = table.find_all('tr')



        #     item = doc.to_item()
        #     yield item